# üîß Feature Engineering - Pipeline de Dados para Credit Scoring

Este reposit√≥rio cont√©m o Projeto Integrado de **Feature Engineering** do **MBA em Data Science & AI da FIAP (10DTSR)**.

O objetivo foi construir um modelo de classifica√ß√£o de risco de cr√©dito (Maus vs. Bons pagadores) a partir de um *dataset* **grande, complexo e com dados brutos** (`credit.csv`). O foco principal do projeto n√£o estava na performance final do modelo, mas sim no processo iterativo de **limpeza de dados, tratamento de nulos, transforma√ß√£o de features e sele√ß√£o de features** em larga escala.

---

## ‚öôÔ∏è O Desafio: Dados Brutos e Desbalanceados

O *dataset* original apresentava diversos desafios de engenharia de dados:
* Mais de 50 colunas com nomes n√£o padronizados.
* M√∫ltiplas colunas com alta cardinalidade (ex: Cidades, Bairros).
* Grande volume de dados nulos (Missing Values) em colunas cr√≠ticas.
* Mistura de dados num√©ricos e categ√≥ricos (strings).
* Classes de alvo (`ROTULO_ALVO_MAU=1`) desbalanceadas (aprox. 27% "maus").

## üîÑ Pipeline de Engenharia de Features (Iterativo)

Foram realizadas m√∫ltiplas tentativas para processar os dados, comparando os resultados:

### Tentativa 1: Apenas Num√©ricas (Drop NA)
* **Estrat√©gia:** Eliminar todas as colunas categ√≥ricas e todas as linhas com valores nulos.
* **Resultado:** Modelo com performance muito ruim (perda excessiva de dados).

### Tentativa 2: Apenas Num√©ricas (Imputa√ß√£o de Nulos)
* **Estrat√©gia:** Manter apenas colunas num√©ricas, mas substituir nulos pela mediana (para `MESES_RESIDENCIA`) ou por uma nova categoria (ex: -1000).
* **Resultado:** Melhor que a Tentativa 1, mas ainda descartando o potencial de dados categ√≥ricos.

### Tentativa 3: One-Hot Encoding (Pandas)
* **Estrat√©gia:** Selecionar colunas categ√≥ricas de baixa cardinalidade (ex: `SEXO`, `ESTADO_RESIDENCIAL`) e aplicar `pd.get_dummies` (One-Hot Encoding).
* **Resultado:** Modelo com `recall` muito baixo (0.09), indicando que o desbalanceamento da base estava levando o modelo a ignorar a classe minorit√°ria (maus pagadores).

### Solu√ß√£o Final: Pipeline Robusto com PySpark e Embedded Selection

Para lidar com a escala e complexidade, o processo foi refeito utilizando **PySpark** para o pr√©-processamento (ETL) e **XGBoost** para a sele√ß√£o de features.

1.  **ETL com PySpark:**
    * Leitura dos dados brutos no Spark.
    * Renomea√ß√£o e sele√ß√£o de colunas.
    * Mapeamento manual de colunas categ√≥ricas (ex: `SEXO` M/F para 1/0).
    * Imputa√ß√£o de nulos (`fillna`) com mediana (calculada via `approxQuantile`) e valores *placeholder*.
    * Convers√£o do DataFrame Spark de volta para Pandas para modelagem.

2.  **Modelagem e Embedded Feature Selection (XGBoost):**
    * Treinamento de um primeiro modelo `XGBClassifier`.
    * Extra√ß√£o da `feature_importance_` do modelo treinado.
    * **Sele√ß√£o de Features:** Dele√ß√£o autom√°tica de todas as colunas com import√¢ncia < 1%.
    * Treinamento de um novo modelo **final**, utilizando apenas o *subset* de features mais importantes.
    * **Resultado:** Um modelo mais leve, r√°pido e com melhor capacidade de generaliza√ß√£o, focado apenas nas vari√°veis que realmente impactam o resultado.

---

## üõ†Ô∏è Stack Tecnol√≥gica

* **Linguagem:** Python
* **Processamento de Dados (ETL):** PySpark, Pandas
* **Modelagem:** Scikit-learn (`train_test_split`, `classification_report`)
* **Algoritmo:** XGBoost (`XGBClassifier`)
* **T√©cnica de Sele√ß√£o:** Embedded Feature Selection (baseada em import√¢ncia)

## üë• Autores

* *(Adicione os nomes/links dos seus colegas de grupo aqui)*
